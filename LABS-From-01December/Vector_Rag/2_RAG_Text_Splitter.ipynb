{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f532338",
   "metadata": {},
   "source": [
    "## Text splitters & RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d57b35-5ddf-4c0b-bb01-034d881890e2",
   "metadata": {},
   "source": [
    "\n",
    "Building effective RAG systems starts with splitting documents into meaningful, searchable chunks.\n",
    "\n",
    "LangChainâ€™s text splitters help break large PDFs, reports, and manuals into clean segments that improve embedding quality and reduce hallucinations.\n",
    "\n",
    "This tutorial introduces the essentials of text splitting, embedding, and retrievalâ€”giving you the foundations to build accurate, efficient RAG pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de114698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import (\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    SentenceTransformersTokenTextSplitter,\n",
    "    TextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e22c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77f11ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the text file and the persistent directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "file_path = os.path.join(current_dir, \"data\", \"IOT.pdf\")\n",
    "db_dir = os.path.join(current_dir, \"db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2bed9c-283c-44e5-afec-b1c7b5fa8e3d",
   "metadata": {},
   "source": [
    "#### load pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83865b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6872a-b102-4732-a778-e09a9e3f7b1d",
   "metadata": {},
   "source": [
    "* Reference link for built-in document loader in langchain\n",
    "* https://docs.langchain.com/oss/python/integrations/document_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd57a39-1325-4cc9-9153-a6952157530d",
   "metadata": {},
   "source": [
    "#### Text splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e76dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split document content\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca37295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Document Chunks Information ---\n",
      "Number of document chunks: 4\n",
      "Sample chunk:\n",
      "Why is Internet of Things (IoT) so important? \n",
      "Over the past few years, IoT has become one of the most important technologies of the \n",
      "21st century. Now that we can connect everyday objectsâ€”kitchen appliances, cars, \n",
      "thermostats, baby monitorsâ€”to the internet via embedded devices, seamless \n",
      "communication is possible between people, processes, and things. \n",
      " \n",
      "By means of low-cost computing, the cloud, big data, analytics, and mobile \n",
      "technologies, physical things can share and collect data with minimal human \n",
      "intervention. In this hyperconnected world, digital systems can record, monitor, and \n",
      "adjust each interaction between connected things. The physical world meets the digital \n",
      "worldâ€”and they cooperate. \n",
      " \n",
      "What technologies have made IoT possible? \n",
      "While the idea of IoT has been in existence for a long time, a collection of recent \n",
      "advances in a number of different technologies has made it practical.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display information about the split documents\n",
    "print(\"\\n--- Document Chunks Information ---\")\n",
    "print(f\"Number of document chunks: {len(docs)}\")\n",
    "print(f\"Sample chunk:\\n{docs[0].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdef6e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating embeddings ---\n",
      "\n",
      "--- Finished creating embeddings ---\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "print(\"\\n--- Creating embeddings ---\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "print(\"\\n--- Finished creating embeddings ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffc2ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store and persist it automatically\n",
    "\n",
    "# Function to create and persist vector store\n",
    "def create_vector_store(docs, store_name):\n",
    "    persistent_directory = os.path.join(db_dir, store_name)\n",
    "    if not os.path.exists(persistent_directory):\n",
    "        print(f\"\\n--- Creating vector store {store_name} ---\")\n",
    "        db = Chroma.from_documents(\n",
    "            docs, embeddings, persist_directory=persistent_directory\n",
    "        )\n",
    "        print(f\"--- Finished creating vector store {store_name} ---\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Vector store {store_name} already exists. No need to initialize.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf32434-a96c-4fec-8eff-d1ebbcc9a939",
   "metadata": {},
   "source": [
    "#### 1. Character-based Splitting\n",
    "* Splits text into chunks based on a specified number of characters.\n",
    "* Useful for consistent chunk sizes regardless of content structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ab54e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Character-based Splitting ---\n",
      "\n",
      "--- Creating vector store chroma_db_char ---\n",
      "--- Finished creating vector store chroma_db_char ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Using Character-based Splitting ---\")\n",
    "char_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "char_docs = char_splitter.split_documents(documents)\n",
    "create_vector_store(char_docs, \"chroma_db_char\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1d9f6e-967e-45be-8399-40a529589ff2",
   "metadata": {},
   "source": [
    "#### 2. Sentence-based Splitting\n",
    "* Splits text into chunks based on sentences, ensuring chunks end at sentence boundaries.\n",
    "\n",
    "* Counts tokens using the SentenceTransformer modelâ€™s own tokenizer so chunks never exceed the modelâ€™s maximum token limit.\n",
    "\n",
    "* Tries to split text first at meaningful breakpointsâ€”paragraphs (\\n\\n), sentences (., ?, !)â€”similar to a recursive splitting strategy.\n",
    "\n",
    "* If a paragraph or sentence is too long, it falls back to finer boundaries (single \\n, then spaces, then characters) until the chunk fits the token limit.\n",
    "\n",
    "* Uses the optional chunk_overlap parameter to repeat a portion of tokens across chunks to maintain context continuity.\n",
    "\n",
    "* Ideal for maintaining semantic coherence within chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d1c276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Sentence-based Splitting ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ea8fb91d0e469b96f9d57e659e6189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vyanktesh.l\\Documents\\FDE\\genai_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vyanktesh.l\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487f42bc125948839bad758b88a457a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d119026cd1494e2195f53006d3af4c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be10d54a7c1f4b46a0a432c1bd97c4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102234a884c942e78a0974dbf1b9258b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c40052edd5496eb71bd340fc29d520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a919eb88bc4821add4a9f7c291a8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ace3e126f94c698f4be9d5c5bc0db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b443d34616cc4c7198fa927bd58b3806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71230d894f8043669cc2367f4f41f4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61247e4da6474c7bae7c931002a33fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating vector store chroma_db_sent ---\n",
      "--- Finished creating vector store chroma_db_sent ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Using Sentence-based Splitting ---\")\n",
    "sent_splitter = SentenceTransformersTokenTextSplitter(chunk_size=1000)\n",
    "sent_docs = sent_splitter.split_documents(documents)\n",
    "create_vector_store(sent_docs, \"chroma_db_sent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34e2fab-36dd-48f7-91c1-fdd8dc1d06f7",
   "metadata": {},
   "source": [
    "#### 3. Token-based Splitting\n",
    "* Splits text into chunks based on tokens (words or subwords), using tokenizers\n",
    "* Useful for transformer models with strict token limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bab23e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Token-based Splitting ---\n",
      "\n",
      "--- Creating vector store chroma_db_token ---\n",
      "--- Finished creating vector store chroma_db_token ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Using Token-based Splitting ---\")\n",
    "token_splitter = TokenTextSplitter(chunk_overlap=0, chunk_size=512)\n",
    "token_docs = token_splitter.split_documents(documents)\n",
    "create_vector_store(token_docs, \"chroma_db_token\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f68bb9-15f5-4c2d-990b-548880c4ca8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84d91305-c145-473b-b42f-28cca3170d3a",
   "metadata": {},
   "source": [
    "#### 4. Recursive Character-based Splitting\n",
    "* Attempts to split text at natural boundaries (sentences, paragraphs) within character limit.\n",
    "* Balances between maintaining coherence and adhering to character limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e12d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Recursive Character-based Splitting ---\n",
      "\n",
      "--- Creating vector store chroma_db_rec_char ---\n",
      "--- Finished creating vector store chroma_db_rec_char ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Using Recursive Character-based Splitting ---\")\n",
    "rec_char_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100)\n",
    "rec_char_docs = rec_char_splitter.split_documents(documents)\n",
    "create_vector_store(rec_char_docs, \"chroma_db_rec_char\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c9edf-b368-4a42-8c9b-58177c37f852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ffa0a1-e763-4f37-b62b-2260d90c26a9",
   "metadata": {},
   "source": [
    "#### 5. Custom Splitting\n",
    "* Allows creating custom splitting logic based on specific requirements.\n",
    "* Useful for documents with unique structure that standard splitters can't handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "050e9139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Custom Splitting ---\n",
      "\n",
      "--- Creating vector store chroma_db_custom ---\n",
      "--- Finished creating vector store chroma_db_custom ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Using Custom Splitting ---\")\n",
    "\n",
    "\n",
    "class CustomTextSplitter(TextSplitter):\n",
    "    def split_text(self, text):\n",
    "        # Custom logic for splitting text\n",
    "        return text.split(\"\\n\\n\")  # Example: split by paragraphs\n",
    "\n",
    "\n",
    "custom_splitter = CustomTextSplitter()\n",
    "custom_docs = custom_splitter.split_documents(documents)\n",
    "create_vector_store(custom_docs, \"chroma_db_custom\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "248bacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query a vector store\n",
    "def query_vector_store(store_name, query):\n",
    "    persistent_directory = os.path.join(db_dir, store_name)\n",
    "    if os.path.exists(persistent_directory):\n",
    "        print(f\"\\n--- Querying the Vector Store {store_name} ---\")\n",
    "        db = Chroma(\n",
    "            persist_directory=persistent_directory, embedding_function=embeddings\n",
    "        )\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity_score_threshold\",\n",
    "            search_kwargs={\"k\": 1, \"score_threshold\": 0.1},\n",
    "        )\n",
    "        relevant_docs = retriever.invoke(query)\n",
    "        # Display the relevant results with metadata\n",
    "        print(f\"\\n--- Relevant Documents for {store_name} ---\")\n",
    "        for i, doc in enumerate(relevant_docs, 1):\n",
    "            print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "            if doc.metadata:\n",
    "                print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")\n",
    "    else:\n",
    "        print(f\"Vector store {store_name} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9461883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the user's question\n",
    "query = \"What technologies have made IoT possible?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4e1cb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Querying the Vector Store chroma_db_char ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vyanktesh.l\\AppData\\Local\\Temp\\ipykernel_43180\\760185032.py:6: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents for chroma_db_char ---\n",
      "Document 1:\n",
      "Why is Internet of Things (IoT) so important? \n",
      "Over the past few years, IoT has become one of the most important technologies of the \n",
      "21st century. Now that we can connect everyday objectsâ€”kitchen appliances, cars, \n",
      "thermostats, baby monitorsâ€”to the internet via embedded devices, seamless \n",
      "communication is possible between people, processes, and things. \n",
      " \n",
      "By means of low-cost computing, the cloud, big data, analytics, and mobile \n",
      "technologies, physical things can share and collect data with minimal human \n",
      "intervention. In this hyperconnected world, digital systems can record, monitor, and \n",
      "adjust each interaction between connected things. The physical world meets the digital \n",
      "worldâ€”and they cooperate. \n",
      " \n",
      "What technologies have made IoT possible? \n",
      "While the idea of IoT has been in existence for a long time, a collection of recent \n",
      "advances in a number of different technologies has made it practical. \n",
      " \n",
      "Access to low-cost, low-power sensor technology. Affordable and reliable sensors are \n",
      "making IoT technology possible for more manufacturers. \n",
      "Connectivity. A host of network protocols for the internet has made it easy to connect \n",
      "sensors to the cloud and to other â€œthingsâ€ for efficient data transfer. \n",
      "Cloud computing platforms. The increase in the availability of cloud platforms enables \n",
      "both businesses and consumers to access the infrastructure they need to scale up \n",
      "without actually having to manage it all. \n",
      "Machine learning and analytics. With advances in machine learning and analytics, \n",
      "along with access to varied and vast amounts of data stored in the cloud, businesses \n",
      "can gather insights faster and more easily. The emergence of these allied technologies \n",
      "continues to push the boundaries of IoT and the data produced by IoT also feeds these \n",
      "technologies. \n",
      "Conversational artificial intelligence (AI). Advances in neural networks have brought \n",
      "natural-language processing (NLP) to IoT devices (such as digital personal assistants \n",
      "Alexa, Cortana, and Siri) and made them appealing, affordable, and viable for home \n",
      "use. \n",
      "What is industrial IoT?\n",
      "\n",
      "Source: C:\\Users\\vyanktesh.l\\Documents\\FDE\\FullStack\\FDE_first_web_App\\LABS-From-01December\\Vector_Rag\\data\\IOT.pdf\n",
      "\n",
      "\n",
      "--- Querying the Vector Store chroma_db_sent ---\n",
      "\n",
      "--- Relevant Documents for chroma_db_sent ---\n",
      "Document 1:\n",
      "why is internet of things ( iot ) so important? over the past few years, iot has become one of the most important technologies of the 21st century. now that we can connect everyday objects â€” kitchen appliances, cars, thermostats, baby monitors â€” to the internet via embedded devices, seamless communication is possible between people, processes, and things. by means of low - cost computing, the cloud, big data, analytics, and mobile technologies, physical things can share and collect data with minimal human intervention. in this hyperconnected world, digital systems can record, monitor, and adjust each interaction between connected things. the physical world meets the digital world â€” and they cooperate. what technologies have made iot possible? while the idea of iot has been in existence for a long time, a collection of recent advances in a number of different technologies has made it practical. access to low - cost, low - power sensor technology. affordable and reliable sensors are making iot technology possible for more manufacturers. connectivity. a host of network protocols for the internet has made it easy to connect sensors to the cloud and to other â€œ things â€ for efficient data transfer. cloud computing platforms. the increase in the availability of cloud platforms enables both businesses and consumers to access the infrastructure they need to scale up without actually having to manage it all. machine learning and analytics. with advances in machine learning and analytics, along with access to varied and vast amounts of data stored in the cloud, businesses can gather insights faster and more easily. the emergence of these allied technologies continues to push the boundaries of iot and the data produced by iot also feeds these technologies. conversational artificial intelligence ( ai ). advances in neural networks have brought natural - language processing ( nlp ) to iot devices ( such as digital personal assistants alexa, cortana, and siri ) and made them appealing, affordable, and viable for\n",
      "\n",
      "Source: C:\\Users\\vyanktesh.l\\Documents\\FDE\\FullStack\\FDE_first_web_App\\LABS-From-01December\\Vector_Rag\\data\\IOT.pdf\n",
      "\n",
      "\n",
      "--- Querying the Vector Store chroma_db_token ---\n",
      "\n",
      "--- Relevant Documents for chroma_db_token ---\n",
      "Document 1:\n",
      "Why is Internet of Things (IoT) so important? \n",
      "Over the past few years, IoT has become one of the most important technologies of the \n",
      "21st century. Now that we can connect everyday objectsâ€”kitchen appliances, cars, \n",
      "thermostats, baby monitorsâ€”to the internet via embedded devices, seamless \n",
      "communication is possible between people, processes, and things. \n",
      " \n",
      "By means of low-cost computing, the cloud, big data, analytics, and mobile \n",
      "technologies, physical things can share and collect data with minimal human \n",
      "intervention. In this hyperconnected world, digital systems can record, monitor, and \n",
      "adjust each interaction between connected things. The physical world meets the digital \n",
      "worldâ€”and they cooperate. \n",
      " \n",
      "What technologies have made IoT possible? \n",
      "While the idea of IoT has been in existence for a long time, a collection of recent \n",
      "advances in a number of different technologies has made it practical. \n",
      " \n",
      "Access to low-cost, low-power sensor technology. Affordable and reliable sensors are \n",
      "making IoT technology possible for more manufacturers. \n",
      "Connectivity. A host of network protocols for the internet has made it easy to connect \n",
      "sensors to the cloud and to other â€œthingsâ€ for efficient data transfer. \n",
      "Cloud computing platforms. The increase in the availability of cloud platforms enables \n",
      "both businesses and consumers to access the infrastructure they need to scale up \n",
      "without actually having to manage it all. \n",
      "Machine learning and analytics. With advances in machine learning and analytics, \n",
      "along with access to varied and vast amounts of data stored in the cloud, businesses \n",
      "can gather insights faster and more easily. The emergence of these allied technologies \n",
      "continues to push the boundaries of IoT and the data produced by IoT also feeds these \n",
      "technologies. \n",
      "Conversational artificial intelligence (AI). Advances in neural networks have brought \n",
      "natural-language processing (NLP) to IoT devices (such as digital personal assistants \n",
      "Alexa, Cortana, and Siri) and made them appealing, affordable, and viable for home \n",
      "use. \n",
      "What is industrial IoT?\n",
      "\n",
      "Source: C:\\Users\\vyanktesh.l\\Documents\\FDE\\FullStack\\FDE_first_web_App\\LABS-From-01December\\Vector_Rag\\data\\IOT.pdf\n",
      "\n",
      "\n",
      "--- Querying the Vector Store chroma_db_rec_char ---\n",
      "\n",
      "--- Relevant Documents for chroma_db_rec_char ---\n",
      "Document 1:\n",
      "advances in a number of different technologies has made it practical. \n",
      " \n",
      "Access to low-cost, low-power sensor technology. Affordable and reliable sensors are \n",
      "making IoT technology possible for more manufacturers. \n",
      "Connectivity. A host of network protocols for the internet has made it easy to connect \n",
      "sensors to the cloud and to other â€œthingsâ€ for efficient data transfer. \n",
      "Cloud computing platforms. The increase in the availability of cloud platforms enables \n",
      "both businesses and consumers to access the infrastructure they need to scale up \n",
      "without actually having to manage it all. \n",
      "Machine learning and analytics. With advances in machine learning and analytics, \n",
      "along with access to varied and vast amounts of data stored in the cloud, businesses \n",
      "can gather insights faster and more easily. The emergence of these allied technologies \n",
      "continues to push the boundaries of IoT and the data produced by IoT also feeds these \n",
      "technologies.\n",
      "\n",
      "Source: C:\\Users\\vyanktesh.l\\Documents\\FDE\\FullStack\\FDE_first_web_App\\LABS-From-01December\\Vector_Rag\\data\\IOT.pdf\n",
      "\n",
      "\n",
      "--- Querying the Vector Store chroma_db_custom ---\n",
      "\n",
      "--- Relevant Documents for chroma_db_custom ---\n",
      "Document 1:\n",
      "Why is Internet of Things (IoT) so important? \n",
      "Over the past few years, IoT has become one of the most important technologies of the \n",
      "21st century. Now that we can connect everyday objectsâ€”kitchen appliances, cars, \n",
      "thermostats, baby monitorsâ€”to the internet via embedded devices, seamless \n",
      "communication is possible between people, processes, and things. \n",
      " \n",
      "By means of low-cost computing, the cloud, big data, analytics, and mobile \n",
      "technologies, physical things can share and collect data with minimal human \n",
      "intervention. In this hyperconnected world, digital systems can record, monitor, and \n",
      "adjust each interaction between connected things. The physical world meets the digital \n",
      "worldâ€”and they cooperate. \n",
      " \n",
      "What technologies have made IoT possible? \n",
      "While the idea of IoT has been in existence for a long time, a collection of recent \n",
      "advances in a number of different technologies has made it practical. \n",
      " \n",
      "Access to low-cost, low-power sensor technology. Affordable and reliable sensors are \n",
      "making IoT technology possible for more manufacturers. \n",
      "Connectivity. A host of network protocols for the internet has made it easy to connect \n",
      "sensors to the cloud and to other â€œthingsâ€ for efficient data transfer. \n",
      "Cloud computing platforms. The increase in the availability of cloud platforms enables \n",
      "both businesses and consumers to access the infrastructure they need to scale up \n",
      "without actually having to manage it all. \n",
      "Machine learning and analytics. With advances in machine learning and analytics, \n",
      "along with access to varied and vast amounts of data stored in the cloud, businesses \n",
      "can gather insights faster and more easily. The emergence of these allied technologies \n",
      "continues to push the boundaries of IoT and the data produced by IoT also feeds these \n",
      "technologies. \n",
      "Conversational artificial intelligence (AI). Advances in neural networks have brought \n",
      "natural-language processing (NLP) to IoT devices (such as digital personal assistants \n",
      "Alexa, Cortana, and Siri) and made them appealing, affordable, and viable for home \n",
      "use. \n",
      "What is industrial IoT?\n",
      "\n",
      "Source: C:\\Users\\vyanktesh.l\\Documents\\FDE\\FullStack\\FDE_first_web_App\\LABS-From-01December\\Vector_Rag\\data\\IOT.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query each vector store\n",
    "query_vector_store(\"chroma_db_char\", query)\n",
    "query_vector_store(\"chroma_db_sent\", query)\n",
    "query_vector_store(\"chroma_db_token\", query)\n",
    "query_vector_store(\"chroma_db_rec_char\", query)\n",
    "query_vector_store(\"chroma_db_custom\", query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc78a120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7054d847-7677-44f7-aa18-8cc9df61fb54",
   "metadata": {},
   "source": [
    "#### ðŸ§© Document Structureâ€“Based Splitting\n",
    "Some documents have an inherent structure â€” such as HTML, Markdown, or JSON files.\n",
    "Splitting based on their structure helps preserve meaning and improve downstream performance.\n",
    "\n",
    "âœ… Key Benefits\n",
    "* Preserves the logical organization of the document\n",
    "* Maintains context within each chunk\n",
    "* Improves retrieval and summarization accuracy\n",
    "\n",
    "ðŸ§± Examples\n",
    "* Markdown â†’ Split by headers (#, ##, ###)\n",
    "* HTML â†’ Split by tags (&lt; div&gt;, &lt;p&gt;, &lt;section&gt;)\n",
    "* JSON â†’ Split by object or array elements\n",
    "* Code â†’ Split by functions, classes, or logical blocks\n",
    "\n",
    "\n",
    "âš™ï¸ Available Splitters\n",
    "* SplitMarkdown\n",
    "* SplitJSON\n",
    "* SplitCode\n",
    "* SplitHTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40a5b18f-9e36-4cc6-a0cd-8e6e9759e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Header 1': 'Section 1'}, page_content='This section contains an important table and list'), Document(metadata={'Header 1': 'Section 1'}, page_content='that should not be split across chunks.'), Document(metadata={'Header 1': 'Section 1'}, page_content='Item Quantity Price Apples 10 $1.00 Oranges 5 $0.50 Bananas 50 $1.50'), Document(metadata={'Header 2': 'Subsection 1.1'}, page_content='Additional text in subsection 1.1 that is'), Document(metadata={'Header 2': 'Subsection 1.1'}, page_content='separated from the table and list. Here is a'), Document(metadata={'Header 2': 'Subsection 1.1'}, page_content=\"detailed list: Item 1: Description of item 1, which is quite detailed and important. Item 2: Description of item 2, which also contains significant information. Item 3: Description of item 3, another item that we don't want to split across chunks.\")]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vyanktesh.l\\AppData\\Local\\Temp\\ipykernel_43180\\603221681.py:47: LangChainBetaWarning: The class `HTMLSemanticPreservingSplitter` is in beta. It is actively being worked on, so the API may change.\n",
      "  splitter = HTMLSemanticPreservingSplitter(\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLSemanticPreservingSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1>Section 1</h1>\n",
    "            <p>This section contains an important table and list that should not be split across chunks.</p>\n",
    "            <table>\n",
    "                <tr>\n",
    "                    <th>Item</th>\n",
    "                    <th>Quantity</th>\n",
    "                    <th>Price</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>Apples</td>\n",
    "                    <td>10</td>\n",
    "                    <td>$1.00</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>Oranges</td>\n",
    "                    <td>5</td>\n",
    "                    <td>$0.50</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>Bananas</td>\n",
    "                    <td>50</td>\n",
    "                    <td>$1.50</td>\n",
    "                </tr>\n",
    "            </table>\n",
    "            <h2>Subsection 1.1</h2>\n",
    "            <p>Additional text in subsection 1.1 that is separated from the table and list.</p>\n",
    "            <p>Here is a detailed list:</p>\n",
    "            <ul>\n",
    "                <li>Item 1: Description of item 1, which is quite detailed and important.</li>\n",
    "                <li>Item 2: Description of item 2, which also contains significant information.</li>\n",
    "                <li>Item 3: Description of item 3, another item that we don't want to split across chunks.</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on = [(\"h1\", \"Header 1\"), (\"h2\", \"Header 2\")]\n",
    "\n",
    "splitter = HTMLSemanticPreservingSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    "    max_chunk_size=50,\n",
    "    elements_to_preserve=[\"table\", \"ul\"],\n",
    ")\n",
    "\n",
    "documents = splitter.split_text(html_string)\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f829f0d-c9eb-4d29-b64c-da92215faafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451fc82-d67e-4db9-a81b-34c3be97a216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cce6699-c806-4421-ae65-fd285309e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2490713b-b3a5-4236-990f-c7e6c850d086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='def hello_world():\\n    print(\"Hello, World!\")'),\n",
       " Document(metadata={}, page_content='# Call the function\\nhello_world()')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3cb3b-8ef1-446d-b105-bb2f806cf4fc",
   "metadata": {},
   "source": [
    "#To view the full list of supported languages:\n",
    "\n",
    "\n",
    "[e.value for e in Language]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4e1a3-7503-4b34-9424-3b35291c0b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd5fa1-35cc-4018-aecd-5dcf77747b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25a93744-eeab-49cf-81e1-93b25a24c3c3",
   "metadata": {},
   "source": [
    "### Retrieval and Generation:\n",
    "The generation step involves combining the information retrieved from the indexed chunks with a language model to generate a final output.\n",
    "\n",
    "We can put it all together into a chain that takes a question, retrieves relevant documents, constructs a prompt, passes that to a model, and parses the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e128d48c-08fd-4719-82fb-935e0b6977b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_name=\"chroma_db_char\"\n",
    "persistent_directory = os.path.join(db_dir, store_name)\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=embeddings)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 1, \"score_threshold\": 0.1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310cae6-71ce-4c96-82cb-feac11a77d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "076d0f0f-ffa2-4959-8d52-dc452b3b0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59fda34a-a636-4265-bb09-c748ae8e5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad95c40-8fdc-4401-8549-563d4b9cdf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7d5d784-5b07-46df-9f07-5be0863dfee6",
   "metadata": {},
   "source": [
    "This function runs a RAG pipeline by retrieving relevant documents, assembling their content into a context string, and passing it to the prompt. The prompt, LLM, and parser form a RAG chain that generates a final answer grounded in the retrieved context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "314a7f22-204d-42cd-8d47-4fac87490d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rag_chain(question):\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    \n",
    "    chain = prompt | llm | parser\n",
    "    return chain.invoke({\"context\": context, \"input\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9073b74-ae7a-47c2-b142-7cc14c1367ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's question\n",
    "query = \"What technologies have made IoT possible?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c2215-59f7-425a-b4e6-cc3b9d2dd323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fafeccc3-f52c-42d4-8ef0-e602aaa728d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The technologies that have made IoT possible include low-cost, low-power sensor technology for affordable and reliable device connectivity, various network protocols for efficient data transfer, and cloud computing platforms that provide scalable infrastructure. Advances in machine learning and analytics allow for faster insights from the vast data collected. Additionally, developments in conversational artificial intelligence contribute to user-friendly IoT devices.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rag_chain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c406811-0663-4b83-923f-c1131456877c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
